#!/usr/bin/env python3
"""
Magyar receptek adatfeldolgoz√°sa √©s normaliz√°l√°sa - TELJES VERZI√ì
Val√≥s hungarian_recipes_github.csv integr√°l√°sa k√ºls≈ë k√©p URL-ekkel
"""

import pandas as pd
import numpy as np
from pathlib import Path
import os
import sys
import re
import json

class HungarianRecipeProcessor:
    """Magyar receptek feldolgoz√°sa √©s normaliz√°l√°sa k√ºls≈ë k√©pekkel"""
    
    def __init__(self, csv_file_path="hungarian_recipes_github.csv"):
        self.csv_path = csv_file_path
        self.processed_data = None
        
    def load_and_validate_data(self):
        """CSV bet√∂lt√©se √©s valid√°l√°sa"""
        try:
            print(f"üìä Bet√∂lt√©s: {self.csv_path}")
            
            # T√∂bbf√©le encoding pr√≥b√°l√°sa
            encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(self.csv_path, encoding=encoding)
                    print(f"‚úÖ Sikeres bet√∂lt√©s {encoding} encoding-gal")
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                print("‚ùå Nem siker√ºlt bet√∂lteni egyik encoding-gal sem")
                return None
            
            print(f"‚úÖ Sikeresen bet√∂ltve: {len(df)} recept")
            print(f"üìã Oszlopok: {list(df.columns)}")
            
            # K√∂telez≈ë oszlopok ellen≈ërz√©se
            required_columns = ['name', 'ingredients', 'env_score', 'nutri_score', 'meal_score']
            optional_columns = ['instructions', 'images']
            
            missing_required = [col for col in required_columns if col not in df.columns]
            if missing_required:
                print(f"‚ùå Hi√°nyz√≥ k√∂telez≈ë oszlopok: {missing_required}")
                return None
            
            missing_optional = [col for col in optional_columns if col not in df.columns]
            if missing_optional:
                print(f"‚ö†Ô∏è Hi√°nyz√≥ opcion√°lis oszlopok: {missing_optional}")
                # L√©trehozzuk az √ºres oszlopokat
                for col in missing_optional:
                    df[col] = ''
            
            # Alapvet≈ë adatmin≈ës√©g ellen≈ërz√©s
            print(f"üîç Adatmin≈ës√©g ellen≈ërz√©s:")
            print(f"   √úres nevek: {df['name'].isna().sum()}")
            print(f"   √úres √∂sszetev≈ëk: {df['ingredients'].isna().sum()}")
            print(f"   Env_score tartom√°ny: {df['env_score'].min():.2f} - {df['env_score'].max():.2f}")
            print(f"   Nutri_score tartom√°ny: {df['nutri_score'].min():.2f} - {df['nutri_score'].max():.2f}")
            print(f"   Meal_score tartom√°ny: {df['meal_score'].min():.2f} - {df['meal_score'].max():.2f}")
            
            return df
            
        except FileNotFoundError:
            print(f"‚ùå F√°jl nem tal√°lhat√≥: {self.csv_path}")
            return None
        except Exception as e:
            print(f"‚ùå Hiba a bet√∂lt√©s sor√°n: {e}")
            return None
    
    def process_image_urls(self, images_string):
        """
        K√©p URL-ek feldolgoz√°sa - els≈ë val√≥s URL kiv√°laszt√°sa
        Kezeli a vessz≈ë-separated URL list√°kat √©s id√©z≈ëjeleket
        """
        if pd.isna(images_string) or not images_string or images_string == '':
            return self.get_placeholder_image()
        
        # String √°talak√≠t√°s √©s tiszt√≠t√°s
        images_str = str(images_string).strip()
        
        # Ha √ºres vagy csak whitespace
        if not images_str:
            return self.get_placeholder_image()
        
        try:
            # Comma-separated URLs feldolgoz√°sa
            if ',' in images_str:
                # Split by comma √©s mindegyik URL tiszt√≠t√°sa
                urls = [url.strip().strip('"').strip("'") for url in images_str.split(',')]
            else:
                # Egyetlen URL
                urls = [images_str.strip().strip('"').strip("'")]
            
            # Els≈ë √©rv√©nyes HTTP URL keres√©se
            for url in urls:
                if url and (url.startswith('http://') or url.startswith('https://')):
                    # Tov√°bbi tiszt√≠t√°s - extra karakterek elt√°vol√≠t√°sa
                    cleaned_url = re.sub(r'["\s]+$', '', url)
                    print(f"   üñºÔ∏è K√©p URL: {cleaned_url[:60]}...")
                    return cleaned_url
            
            # Ha nincs √©rv√©nyes URL
            print(f"   ‚ö†Ô∏è Nincs √©rv√©nyes URL: {images_str[:50]}...")
            return self.get_placeholder_image()
            
        except Exception as e:
            print(f"   ‚ùå K√©p URL feldolgoz√°si hiba: {e}")
            return self.get_placeholder_image()
    
    def get_placeholder_image(self):
        """Placeholder k√©p URL visszaad√°sa"""
        return "https://via.placeholder.com/400x300/f8f9fa/6c757d?text=Recept+K%C3%A9p"
    
    def normalize_env_score(self, df):
        """
        K√∂rnyezeti pontsz√°m normaliz√°l√°sa 0-100 sk√°l√°ra
        Magasabb env_score = nagyobb k√∂rnyezeti terhel√©s ‚Üí alacsonyabb normaliz√°lt √©rt√©k
        """
        print("üå± K√∂rnyezeti pontsz√°mok normaliz√°l√°sa...")
        
        # Eredeti tartom√°ny
        env_min = df['env_score'].min()
        env_max = df['env_score'].max()
        print(f"   Eredeti env_score tartom√°ny: {env_min:.2f} - {env_max:.2f}")
        
        # Outlierek kezel√©se (99th percentile alapj√°n)
        env_99th = df['env_score'].quantile(0.99)
        env_1st = df['env_score'].quantile(0.01)
        
        # Clipping extr√©m √©rt√©kekhez
        df['env_score_clipped'] = df['env_score'].clip(env_1st, env_99th)
        
        # Min-Max normaliz√°l√°s 0-100-ra, majd invert√°l√°s
        # Magas eredeti √©rt√©k ‚Üí alacsony normaliz√°lt √©rt√©k (rossz k√∂rnyezetileg)
        df['env_score_normalized'] = 100 - ((df['env_score_clipped'] - df['env_score_clipped'].min()) / 
                                           (df['env_score_clipped'].max() - df['env_score_clipped'].min())) * 100
        
        # Ellen≈ërz√©s
        norm_min = df['env_score_normalized'].min()
        norm_max = df['env_score_normalized'].max()
        print(f"   Normaliz√°lt env_score tartom√°ny: {norm_min:.2f} - {norm_max:.2f}")
        
        return df
    
    def normalize_other_scores(self, df):
        """Nutri_score √©s meal_score normaliz√°l√°sa 0-100 sk√°l√°ra ha sz√ºks√©ges"""
        print("üìä Egy√©b pontsz√°mok normaliz√°l√°sa...")
        
        for score_col in ['nutri_score', 'meal_score']:
            col_min = df[score_col].min()
            col_max = df[score_col].max()
            
            print(f"   {score_col} tartom√°ny: {col_min:.2f} - {col_max:.2f}")
            
            # Ha m√°r 0-100 k√∂z√∂tt van, nem kell normaliz√°lni
            if col_min >= 0 and col_max <= 100:
                print(f"   {score_col} m√°r normaliz√°lt")
                continue
            
            # Min-Max normaliz√°l√°s 0-100-ra
            df[f'{score_col}_normalized'] = ((df[score_col] - col_min) / (col_max - col_min)) * 100
            
            # Eredeti oszlop fel√ºl√≠r√°sa
            df[score_col] = df[f'{score_col}_normalized']
            df.drop(f'{score_col}_normalized', axis=1, inplace=True)
            
            print(f"   {score_col} normaliz√°lva: 0-100")
        
        return df
    
    def calculate_composite_score(self, df):
        """
        Kompozit pontsz√°m sz√°m√≠t√°sa
        comp_score = env_score_normalized * 0.4 + nutri_score * 0.4 + meal_score * 0.2
        """
        print("üî¢ Kompozit pontsz√°m sz√°m√≠t√°sa...")
        
        # S√∫lyok
        env_weight = 0.4
        nutri_weight = 0.4
        meal_weight = 0.2
        
        df['comp_score'] = (
            df['env_score_normalized'] * env_weight +
            df['nutri_score'] * nutri_weight +
            df['meal_score'] * meal_weight
        )
        
        # Statisztik√°k
        comp_min = df['comp_score'].min()
        comp_max = df['comp_score'].max()
        comp_mean = df['comp_score'].mean()
        
        print(f"   Kompozit score tartom√°ny: {comp_min:.2f} - {comp_max:.2f}")
        print(f"   √Åtlagos kompozit score: {comp_mean:.2f}")
        
        return df
    
    def clean_and_prepare_data(self, df):
        """Adatok tiszt√≠t√°sa √©s el≈ëk√©sz√≠t√©se a user study-hoz"""
        print("üßπ Adatok tiszt√≠t√°sa...")
        
        # Hi√°nyz√≥ √©rt√©kek kezel√©se
        original_count = len(df)
        df = df.dropna(subset=['name', 'ingredients'])
        cleaned_count = len(df)
        
        if original_count != cleaned_count:
            print(f"   Elt√°vol√≠tva: {original_count - cleaned_count} hi√°nyos recept")
        
        # K√©p URL-ek feldolgoz√°sa
        print("üñºÔ∏è K√©p URL-ek feldolgoz√°sa...")
        df['processed_images'] = df['images'].apply(self.process_image_urls)
        
        # √úres instrukci√≥k helyettes√≠t√©se
        df['instructions'] = df['instructions'].fillna('R√©szletes elk√©sz√≠t√©si √∫tmutat√≥ hamarosan el√©rhet≈ë.')
        
        # Sz√∂veges mez≈ëk tiszt√≠t√°sa
        text_columns = ['name', 'ingredients', 'instructions']
        for col in text_columns:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()
                # HTML tag-ek elt√°vol√≠t√°sa ha vannak
                df[col] = df[col].str.replace(r'<[^>]+>', '', regex=True)
                # Extra whitespace-ek elt√°vol√≠t√°sa
                df[col] = df[col].str.replace(r'\s+', ' ', regex=True)
        
        # User study kompatibilis oszlopnevekkel
        df_clean = df.rename(columns={
            'name': 'title',
            'env_score_normalized': 'ESI',  # Environmental Score Index
            'nutri_score': 'HSI',           # Health Score Index  
            'meal_score': 'PPI',            # Popularity/Preference Index
            'comp_score': 'composite_score',
            'processed_images': 'images'
        })
        
        # Recipe ID hozz√°ad√°sa
        df_clean['recipeid'] = range(1, len(df_clean) + 1)
        
        # √ñsszetev≈ëk r√∂vid√≠t√©se ha t√∫l hossz√∫ (UI miatt)
        df_clean['ingredients_display'] = df_clean['ingredients'].apply(
            lambda x: x[:300] + '...' if len(str(x)) > 300 else x
        )
        
        # Instrukci√≥k r√∂vid√≠t√©se
        df_clean['instructions_display'] = df_clean['instructions'].apply(
            lambda x: x[:500] + '...' if len(str(x)) > 500 else x
        )
        
        print(f"‚úÖ Tiszt√≠tva: {len(df_clean)} recept k√©szenl√©ti √°llapotban")
        
        return df_clean
    
    def create_sample_for_user_study(self, df, sample_size=50):
        """
        Reprezentat√≠v minta l√©trehoz√°sa a user study-hoz
        K√ºl√∂nb√∂z≈ë score tartom√°nyokb√≥l egyenletesen
        """
        print(f"üéØ User study minta l√©trehoz√°sa ({sample_size} recept)...")
        
        # Ha kevesebb recept van mint a k√©rt minta
        if len(df) <= sample_size:
            print(f"   √ñsszes recept haszn√°lva: {len(df)}")
            return df
        
        # Stratified sampling kompozit score alapj√°n
        try:
            df['score_quartile'] = pd.qcut(df['composite_score'], q=4, labels=['low', 'medium', 'high', 'very_high'])
        except ValueError:
            # Ha nem lehet quartile-ekre osztani (t√∫l kev√©s egyedi √©rt√©k)
            print("   Egyszer≈± random sampling haszn√°lata")
            return df.sample(n=sample_size, random_state=42).reset_index(drop=True)
        
        # Egyenletes eloszl√°s a kvartilisek k√∂z√∂tt
        samples_per_quartile = sample_size // 4
        remainder = sample_size % 4
        
        sample_dfs = []
        for i, quartile in enumerate(['low', 'medium', 'high', 'very_high']):
            quartile_df = df[df['score_quartile'] == quartile]
            
            # Marad√©k az els≈ë kvartilis√©hez
            n_samples = samples_per_quartile + (remainder if i == 0 else 0)
            
            if len(quartile_df) >= n_samples:
                sample = quartile_df.sample(n=n_samples, random_state=42)
            else:
                sample = quartile_df  # Ha kevesebb van, mind
            
            sample_dfs.append(sample)
            print(f"   {quartile}: {len(sample)} recept")
        
        user_study_sample = pd.concat(sample_dfs, ignore_index=True)
        
        # Keverj√ºk meg
        user_study_sample = user_study_sample.sample(frac=1, random_state=42).reset_index(drop=True)
        
        # Recipe ID √∫jrasz√°moz√°sa
        user_study_sample['recipeid'] = range(1, len(user_study_sample) + 1)
        
        # Score quartile oszlop elt√°vol√≠t√°sa
        if 'score_quartile' in user_study_sample.columns:
            user_study_sample.drop('score_quartile', axis=1, inplace=True)
        
        print(f"‚úÖ User study minta k√©sz: {len(user_study_sample)} recept")
        
        return user_study_sample
    
    def generate_statistics_report(self, df):
        """Statisztikai riport az adatokr√≥l"""
        print("\nüìä ADATSTATISZTIK√ÅK")
        print("=" * 50)
        
        print(f"üìà Receptek sz√°ma: {len(df)}")
        print(f"üìã Oszlopok: {len(df.columns)}")
        
        # Score statisztik√°k
        score_columns = ['HSI', 'ESI', 'PPI', 'composite_score']
        for score_col in score_columns:
            if score_col in df.columns:
                mean_val = df[score_col].mean()
                std_val = df[score_col].std()
                min_val = df[score_col].min()
                max_val = df[score_col].max()
                
                print(f"\n{score_col}:")
                print(f"   √Åtlag: {mean_val:.2f} ¬± {std_val:.2f}")
                print(f"   Tartom√°ny: {min_val:.2f} - {max_val:.2f}")
        
        # Top 5 recept kompozit score alapj√°n
        if 'composite_score' in df.columns:
            print(f"\nüèÜ TOP 5 RECEPT (kompozit score):")
            top_recipes = df.nlargest(5, 'composite_score')[['title', 'composite_score', 'HSI', 'ESI', 'PPI']]
            for idx, row in top_recipes.iterrows():
                print(f"   {row['title'][:40]:<40} | Score: {row['composite_score']:.1f}")
        
        # Adatmin≈ës√©g ellen≈ërz√©s
        print(f"\nüîç ADATMIN≈êS√âG:")
        print(f"   Hi√°nyz√≥ c√≠mek: {df['title'].isna().sum()}")
        print(f"   Hi√°nyz√≥ √∂sszetev≈ëk: {df['ingredients'].isna().sum()}")
        print(f"   Hi√°nyz√≥ instrukci√≥k: {df['instructions'].isna().sum()}")
        print(f"   Placeholder k√©pek: {df['images'].str.contains('placeholder').sum()}")
        print(f"   K√ºls≈ë k√©pek: {df['images'].str.contains('http').sum()}")
        
        # K√©p URL statisztik√°k
        if 'images' in df.columns:
            print(f"\nüñºÔ∏è K√âP STATISZTIK√ÅK:")
            total_images = len(df)
            external_images = df['images'].str.contains('http', na=False).sum()
            placeholder_images = df['images'].str.contains('placeholder', na=False).sum()
            
            print(f"   √ñsszes recept: {total_images}")
            print(f"   K√ºls≈ë k√©pek: {external_images} ({external_images/total_images*100:.1f}%)")
            print(f"   Placeholder k√©pek: {placeholder_images} ({placeholder_images/total_images*100:.1f}%)")
    
    def process_all(self, output_path="data/processed_recipes.csv", sample_size=50):
        """Teljes feldolgoz√°si pipeline"""
        print("üöÄ MAGYAR RECEPTEK FELDOLGOZ√ÅSA")
        print("=" * 50)
        
        # 1. Bet√∂lt√©s
        df = self.load_and_validate_data()
        if df is None:
            print("‚ùå Feldolgoz√°s megszak√≠tva - CSV bet√∂lt√©si hiba")
            return False
        
        # 2. K√∂rnyezeti score normaliz√°l√°s
        df = self.normalize_env_score(df)
        
        # 3. Egy√©b score-ok normaliz√°l√°sa
        df = self.normalize_other_scores(df)
        
        # 4. Kompozit score
        df = self.calculate_composite_score(df)
        
        # 5. Tiszt√≠t√°s √©s feldolgoz√°s
        df = self.clean_and_prepare_data(df)
        
        # 6. User study minta
        if sample_size > 0 and len(df) > sample_size:
            df_sample = self.create_sample_for_user_study(df, sample_size)
            self.processed_data = df_sample
        else:
            self.processed_data = df
        
        # 7. Statisztik√°k
        self.generate_statistics_report(self.processed_data)
        
        # 8. Ment√©s
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        self.processed_data.to_csv(output_path, index=False, encoding='utf-8')
        
        print(f"\nüíæ Feldolgozott adatok mentve: {output_path}")
        print(f"üìÅ F√°jlm√©ret: {os.path.getsize(output_path) / 1024:.1f} KB")
        
        # 9. Mintaadatok ki√≠r√°sa
        print(f"\nüìã MINTA RECEPTEK:")
        for i in range(min(3, len(self.processed_data))):
            recipe = self.processed_data.iloc[i]
            print(f"   {i+1}. {recipe['title']}")
            print(f"      K√©p: {recipe['images'][:60]}...")
            print(f"      Scores: HSI={recipe['HSI']:.1f}, ESI={recipe['ESI']:.1f}, PPI={recipe['PPI']:.1f}")
        
        return True

def main():
    """F≈ë feldolgoz√°si script"""
    processor = HungarianRecipeProcessor("hungarian_recipes_github.csv")
    
    # Teljes feldolgoz√°s 50 recepttel a user study-hoz
    success = processor.process_all(
        output_path="data/processed_recipes.csv",
        sample_size=50  # Optim√°lis m√©ret a user study-hoz
    )
    
    if success:
        print("\nüéâ FELDOLGOZ√ÅS SIKERES!")
        print("\nüìã K√∂vetkez≈ë l√©p√©sek:")
        print("1. A processed_recipes.csv tartalmazza a feldolgozott recepteket")
        print("2. A user study automatikusan haszn√°lni fogja a val√≥s recepteket")
        print("3. A k√ºls≈ë k√©pek URL-jei megjelennek a weboldalon")
        print("4. Precision/Recall/F1 metrik√°k sz√°m√≠t√°sa implement√°l√°sra ker√ºl")
    else:
        print("\n‚ùå FELDOLGOZ√ÅS SIKERTELEN!")
        print("Ellen≈ërizd a 'hungarian_recipes_github.csv' f√°jl el√©rhet≈ës√©g√©t √©s strukt√∫r√°j√°t.")

if __name__ == "__main__":
    main()
